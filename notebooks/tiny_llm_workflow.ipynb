{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\tiny_llm\n",
      "Current working directory: d:\\Projects\\tiny_llm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd ..\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyLLM: A Hands-On Introduction to AI/ML and LLMs\n",
    "\n",
    "This Jupyter Notebook serves as a practical guide for students and enthusiasts to delve into the fundamentals of Artificial Intelligence (AI), Machine Learning (ML), Neural Networks (NN), and Large Language Models (LLMs) by building a smaller, more manageable model.\n",
    "\n",
    "Our focus is on creating a \"TinyLLM\" using the **TinyStories dataset**. This dataset is specifically designed to be small and simple, making it ideal for:\n",
    "*   **Learning Core Concepts:** Understand the end-to-end process of an LLM workflow, from data preparation to training and inference.\n",
    "*   **Hardware Accessibility:** Train a functional LLM even on consumer-grade hardware, overcoming common barriers for students.\n",
    "*   **Rapid Experimentation:** Quickly iterate and observe the effects of changes due to faster training times.\n",
    "\n",
    "By working through this notebook, you will gain hands-on experience with:\n",
    "*   Setting up a Python environment for deep learning.\n",
    "*   Loading and processing text data for LLM training.\n",
    "*   Understanding the architecture of a transformer-based language model.\n",
    "*   Training an LLM from scratch.\n",
    "*   Performing interactive text generation (inference).\n",
    "*   Evaluating the performance of your trained model.\n",
    "\n",
    "This project is structured to provide a clear, step-by-step learning path, allowing you to grasp complex concepts through practical application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Before running the model, ensure all necessary Python packages are installed. This project uses `torch`, `transformers`, and `datasets`.\n",
    "\n",
    "Run the following cell to install dependencies from `requirements.txt`. If you are using a virtual environment, make sure it's activated before launching Jupyter, or specify the full path to your Python executable within the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.12.14 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (3.12.14)\n",
      "Requirement already satisfied: aiosignal==1.4.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: certifi==2025.7.14 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2025.7.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: datasets==4.0.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: dill==0.3.8 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (0.3.8)\n",
      "Requirement already satisfied: filelock==3.18.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (3.18.0)\n",
      "Requirement already satisfied: frozenlist==1.7.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (1.7.0)\n",
      "Requirement already satisfied: fsspec==2025.3.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub==0.33.4 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (0.33.4)\n",
      "Requirement already satisfied: idna==3.10 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (3.10)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (3.0.2)\n",
      "Requirement already satisfied: mpmath==1.3.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.6.3 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 18)) (6.6.3)\n",
      "Requirement already satisfied: multiprocess==0.70.16 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (0.70.16)\n",
      "Requirement already satisfied: networkx==3.5 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 20)) (3.5)\n",
      "Requirement already satisfied: numpy==2.3.1 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 21)) (2.3.1)\n",
      "Requirement already satisfied: packaging==25.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 22)) (25.0)\n",
      "Requirement already satisfied: pandas==2.3.1 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 23)) (2.3.1)\n",
      "Requirement already satisfied: propcache==0.3.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 24)) (0.3.2)\n",
      "Requirement already satisfied: pyarrow==20.0.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 25)) (20.0.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 26)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 27)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 28)) (6.0.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 29)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.4 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 30)) (2.32.4)\n",
      "Requirement already satisfied: safetensors==0.5.3 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 31)) (0.5.3)\n",
      "Requirement already satisfied: setuptools==80.9.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 32)) (80.9.0)\n",
      "Requirement already satisfied: six==1.17.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 33)) (1.17.0)\n",
      "Requirement already satisfied: sympy==1.14.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 34)) (1.14.0)\n",
      "Requirement already satisfied: tokenizers==0.21.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 35)) (0.21.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 36)) (4.67.1)\n",
      "Requirement already satisfied: transformers==4.53.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 37)) (4.53.2)\n",
      "Requirement already satisfied: typing_extensions==4.14.1 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 38)) (4.14.1)\n",
      "Requirement already satisfied: tzdata==2025.2 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 39)) (2025.2)\n",
      "Requirement already satisfied: urllib3==2.5.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 40)) (2.5.0)\n",
      "Requirement already satisfied: xxhash==3.5.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 41)) (3.5.0)\n",
      "Requirement already satisfied: yarl==1.20.1 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 42)) (1.20.1)\n",
      "Requirement already satisfied: psutil==5.9.8 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 43)) (5.9.8)\n",
      "Requirement already satisfied: pynvml==12.0.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from -r requirements.txt (line 44)) (12.0.0)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in d:\\projects\\tiny_llm\\.venv\\lib\\site-packages (from pynvml==12.0.0->-r requirements.txt (line 44)) (12.575.51)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Debug Data Loading (Optional)\n",
    "\n",
    "This cell is for debugging the data loading process. It will help determine if the Hugging Face dataset is being loaded correctly or if the fallback text is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\tiny_llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA (NVIDIA GPU) for training.\n",
      "\n",
      "Attempting to load and process the dataset...\n",
      "\n",
      "Loading pre-trained tokenizer: gpt2...\n",
      "Set tokenizer pad_token to eos_token.\n",
      "Tokenizer loaded. Vocabulary Size: 50257\n",
      "Loading and processing dataset from Hugging Face...\n",
      "Dataset tokenized.\n",
      "Dataset processed and grouped.\n",
      "Training data samples: 1657972\n",
      "Validation data samples: 184220\n",
      "\n",
      "--- Data Loading Summary ---\n",
      "Training data samples: 1657972\n",
      "Validation data samples: 184220\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ensure we are in the correct directory\n",
    "%pwd\n",
    "\n",
    "from src.llm_data import load_and_process_dataset\n",
    "\n",
    "print(\"\\nAttempting to load and process the dataset...\")\n",
    "try:\n",
    "    train_data, val_data = load_and_process_dataset()\n",
    "    print(f\"\\n--- Data Loading Summary ---\")\n",
    "    print(f\"Training data samples: {len(train_data)}\")\n",
    "    print(f\"Validation data samples: {len(val_data)}\")\n",
    "    print(\"---------------------------\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during data loading: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the TinyLLM Model\n",
    "\n",
    "This step trains the TinyLLM model using the `src/main_train.py` script. The model will be trained for `100000` iterations on the `TinyStories` dataset and saved to `models/tinystories_llm_v1.pth`.\n",
    "\n",
    "**Note**: This training process can can take a significant amount of time depending on your hardware (CPU/GPU/MPS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TinyLLM model training with real-time output...\n",
      "Using CUDA (NVIDIA GPU) for training.\n",
      "\n",
      "Loading pre-trained tokenizer: gpt2...\n",
      "Set tokenizer pad_token to eos_token.\n",
      "Tokenizer loaded. Vocabulary Size: 50257\n",
      "Loading and processing dataset from Hugging Face...\n",
      "Dataset tokenized.\n",
      "Dataset processed and grouped.\n",
      "Training data samples: 1657972\n",
      "Validation data samples: 184220\n",
      "Model initialized with 32,165,969 parameters.\n",
      "Current working directory: d:\\Projects\\tiny_llm\n",
      "Expected model save path: d:\\Projects\\tiny_llm\\models\\tinystories_llm_v1.pth\n",
      "\n",
      "Starting training on cuda...\n",
      "Step 0: train loss 10.8389, val loss 10.8386, lr 0.000000\n",
      "  Time Spent: 15.69s\n",
      "  Resources: CPU: 21.7% | RAM: 35.7% | GPU: 88% | VRAM: 6.53/15.92 GB\n",
      "Step 500: train loss 0.5258, val loss 0.5251, lr 0.000100\n",
      "  Time Spent: 0h 1m 18s\n",
      "  Estimated Total: 0h 21m 11s\n",
      "  Estimated Remaining: 0h 19m 53s\n",
      "  Resources: CPU: 23.7% | RAM: 37.0% | GPU: 91% | VRAM: 11.24/15.92 GB\n",
      "Step 1000: train loss 0.1692, val loss 0.1702, lr 0.000098\n",
      "  Time Spent: 0h 2m 21s\n",
      "  Estimated Total: 0h 21m 5s\n",
      "  Estimated Remaining: 0h 18m 44s\n",
      "  Resources: CPU: 26.0% | RAM: 37.6% | GPU: 91% | VRAM: 11.24/15.92 GB\n",
      "Step 1500: train loss 0.0842, val loss 0.0870, lr 0.000096\n",
      "  Time Spent: 0h 3m 22s\n",
      "  Estimated Total: 0h 20m 55s\n",
      "  Estimated Remaining: 0h 17m 32s\n",
      "  Resources: CPU: 29.8% | RAM: 38.2% | GPU: 89% | VRAM: 11.20/15.92 GB\n",
      "Step 2000: train loss 0.0553, val loss 0.0563, lr 0.000092\n",
      "  Time Spent: 0h 4m 23s\n",
      "  Estimated Total: 0h 20m 46s\n",
      "  Estimated Remaining: 0h 16m 22s\n",
      "  Resources: CPU: 28.8% | RAM: 38.7% | GPU: 91% | VRAM: 11.18/15.92 GB\n",
      "Step 2500: train loss 0.0398, val loss 0.0417, lr 0.000088\n",
      "  Time Spent: 0h 5m 24s\n",
      "  Estimated Total: 0h 20m 39s\n",
      "  Estimated Remaining: 0h 15m 14s\n",
      "  Resources: CPU: 25.0% | RAM: 39.0% | GPU: 90% | VRAM: 11.20/15.92 GB\n",
      "Step 3000: train loss 0.0325, val loss 0.0316, lr 0.000082\n",
      "  Time Spent: 0h 6m 26s\n",
      "  Estimated Total: 0h 20m 40s\n",
      "  Estimated Remaining: 0h 14m 13s\n",
      "  Resources: CPU: 25.3% | RAM: 39.5% | GPU: 91% | VRAM: 11.18/15.92 GB\n",
      "Step 4000: train loss 0.0222, val loss 0.0222, lr 0.000070\n",
      "  Time Spent: 0h 8m 31s\n",
      "  Estimated Total: 0h 20m 40s\n",
      "  Estimated Remaining: 0h 12m 9s\n",
      "  Resources: CPU: 31.7% | RAM: 43.9% | GPU: 91% | VRAM: 11.16/15.92 GB\n",
      "Step 4500: train loss 0.0189, val loss 0.0194, lr 0.000063\n",
      "  Time Spent: 0h 9m 32s\n",
      "  Estimated Total: 0h 20m 40s\n",
      "  Estimated Remaining: 0h 11m 7s\n",
      "  Resources: CPU: 34.0% | RAM: 44.6% | GPU: 90% | VRAM: 11.18/15.92 GB\n",
      "Step 5000: train loss 0.0170, val loss 0.0178, lr 0.000056\n",
      "  Time Spent: 0h 10m 35s\n",
      "  Estimated Total: 0h 20m 41s\n",
      "  Estimated Remaining: 0h 10m 6s\n",
      "  Resources: CPU: 33.1% | RAM: 44.7% | GPU: 92% | VRAM: 11.20/15.92 GB\n",
      "Step 5500: train loss 0.0155, val loss 0.0153, lr 0.000049\n",
      "  Time Spent: 0h 11m 37s\n",
      "  Estimated Total: 0h 20m 42s\n",
      "  Estimated Remaining: 0h 9m 4s\n",
      "  Resources: CPU: 26.6% | RAM: 41.9% | GPU: 90% | VRAM: 11.19/15.92 GB\n",
      "Step 6000: train loss 0.0149, val loss 0.0153, lr 0.000042\n",
      "  Time Spent: 0h 12m 38s\n",
      "  Estimated Total: 0h 20m 40s\n",
      "  Estimated Remaining: 0h 8m 1s\n",
      "  Resources: CPU: 24.5% | RAM: 42.4% | GPU: 90% | VRAM: 11.15/15.92 GB\n",
      "Step 6500: train loss 0.0139, val loss 0.0135, lr 0.000035\n",
      "  Time Spent: 0h 13m 39s\n",
      "  Estimated Total: 0h 20m 37s\n",
      "  Estimated Remaining: 0h 6m 58s\n",
      "  Resources: CPU: 27.4% | RAM: 39.8% | GPU: 90% | VRAM: 11.06/15.92 GB\n",
      "Step 7000: train loss 0.0126, val loss 0.0129, lr 0.000029\n",
      "  Time Spent: 0h 14m 41s\n",
      "  Estimated Total: 0h 20m 37s\n",
      "  Estimated Remaining: 0h 5m 56s\n",
      "  Resources: CPU: 33.0% | RAM: 40.3% | GPU: 90% | VRAM: 11.22/15.92 GB\n",
      "Step 7500: train loss 0.0118, val loss 0.0119, lr 0.000023\n",
      "  Time Spent: 0h 15m 41s\n",
      "  Estimated Total: 0h 20m 35s\n",
      "  Estimated Remaining: 0h 4m 54s\n",
      "  Resources: CPU: 27.1% | RAM: 41.3% | GPU: 90% | VRAM: 11.28/15.92 GB\n",
      "Step 8000: train loss 0.0113, val loss 0.0120, lr 0.000019\n",
      "  Time Spent: 0h 16m 39s\n",
      "  Estimated Total: 0h 20m 32s\n",
      "  Estimated Remaining: 0h 3m 52s\n",
      "  Resources: CPU: 24.6% | RAM: 41.6% | GPU: 91% | VRAM: 11.25/15.92 GB\n",
      "Step 8500: train loss 0.0109, val loss 0.0114, lr 0.000015\n",
      "  Time Spent: 0h 17m 38s\n",
      "  Estimated Total: 0h 20m 28s\n",
      "  Estimated Remaining: 0h 2m 50s\n",
      "  Resources: CPU: 21.5% | RAM: 41.6% | GPU: 90% | VRAM: 11.25/15.92 GB\n",
      "Step 9000: train loss 0.0107, val loss 0.0110, lr 0.000012\n",
      "  Time Spent: 0h 18m 38s\n",
      "  Estimated Total: 0h 20m 26s\n",
      "  Estimated Remaining: 0h 1m 47s\n",
      "  Resources: CPU: 25.6% | RAM: 41.3% | GPU: 90% | VRAM: 11.03/15.92 GB\n",
      "Step 9500: train loss 0.0099, val loss 0.0103, lr 0.000011\n",
      "  Time Spent: 0h 19m 39s\n",
      "  Estimated Total: 0h 20m 26s\n",
      "  Estimated Remaining: 0h 0m 46s\n",
      "  Resources: CPU: 27.3% | RAM: 41.4% | GPU: 90% | VRAM: 11.06/15.92 GB\n",
      "Step 9999: train loss 0.0098, val loss 0.0094, lr 0.000010\n",
      "  Time Spent: 0h 20m 40s\n",
      "  Estimated Total: 0h 20m 25s\n",
      "  Estimated Remaining: -1h 59m 45s\n",
      "  Resources: CPU: 28.7% | RAM: 41.7% | GPU: 91% | VRAM: 11.06/15.92 GB\n",
      "\n",
      "Training complete!\n",
      "Model saved to models/tinystories_llm_v1.pth\n",
      "\n",
      "Training script finished successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Ensure we are in the correct directory\n",
    "%pwd\n",
    "\n",
    "print(\"Starting TinyLLM model training with real-time output...\")\n",
    "\n",
    "# Construct the command to run the training script\n",
    "# Use sys.executable to ensure the correct Python interpreter (e.g., from a venv) is used\n",
    "command = [sys.executable, \"-m\", \"src.main_train\"]\n",
    "\n",
    "# Execute the command using subprocess.Popen for real-time output\n",
    "# bufsize=1 ensures line-buffered output\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "\n",
    "# Read and print output line by line in real-time\n",
    "for line in process.stdout:\n",
    "    print(line, end='') # end='' prevents extra newlines as print already includes them\n",
    "\n",
    "# Wait for the process to complete and get the return code\n",
    "process.wait()\n",
    "\n",
    "if process.returncode == 0:\n",
    "    print(\"\\nTraining script finished successfully.\")\n",
    "else:\n",
    "    print(f\"\\nTraining script exited with error code {process.returncode}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Interactive Inference\n",
    "\n",
    "After the model has been successfully trained and saved, you can use the `src/main_inference.py` script to interactively generate text.\n",
    "\n",
    "The inference script will load the `tinystories_llm_v1.pth` model and prompt you to enter text. The model will then attempt to complete your input. The generation uses a `temperature` of `0.8` for more varied output.\n",
    "\n",
    "**To exit the interactive session, type `exit` when prompted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.main_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the TinyLLM Model\n",
    "\n",
    "This section allows you to evaluate the trained TinyLLM model using the `src/main_eval.py` script. It includes options to test the Gemini API connection, calculate perplexity, generate sample stories, and perform automated LLM-as-a-Judge evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Gemini API Connection ---\n",
      "Using CUDA (NVIDIA GPU) for training.\n",
      "\n",
      "--- Testing Gemini API Connection ---\n",
      "Successfully connected to Gemini API.\n",
      "\n",
      "--- Running Full Evaluation ---\n",
      "Using CUDA (NVIDIA GPU) for training.\n",
      "Loading model and tokenizer...\n",
      "\n",
      "Loading pre-trained tokenizer: gpt2...\n",
      "Set tokenizer pad_token to eos_token.\n",
      "Tokenizer loaded. Vocabulary Size: 50257\n",
      "Model loaded successfully.\n",
      "Loading and processing dataset from Hugging Face...\n",
      "Dataset tokenized.\n",
      "Dataset processed and grouped.\n",
      "Training data samples: 1657972\n",
      "Validation data samples: 184220\n",
      "\n",
      "Calculating perplexity...\n",
      "Perplexity on validation set: 1.01\n",
      "\n",
      "--- Generating Sample Stories ---\n",
      "\n",
      "Prompt: Once upon a time, in a land far away,\n",
      "Generated Text:\n",
      "Once upon a time, in a land far away,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "\n",
      "Prompt: The little robot woke up and saw\n",
      "Generated Text:\n",
      "The little robot woke up and saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw saw\n",
      "\n",
      "Prompt: A curious cat followed a butterfly and found\n",
      "Generated Text:\n",
      "A curious cat followed a butterfly and found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found found\n",
      "\n",
      "--- Evaluating with LLM-as-a-Judge (Gemini) ---\n",
      "gemini-2.5-flash\n",
      "\n",
      "Raw LLM Judge Response:\n",
      "```json\n",
      "{\n",
      "  \"coherence_score\": 1,\n",
      "  \"creativity_score\": 1,\n",
      "  \"grammar_score\": 1,\n",
      "  \"justification\": \"The story begins with a coherent phrase but immediately dissolves into an extreme repetition of the word 'to', making it entirely illogical, devoid of any creative development, and grammatically incomplete as a sentence.\"\n",
      "}\n",
      "```\n",
      "LLM Judge Evaluation:\n",
      "{\n",
      "  \"coherence_score\": 1,\n",
      "  \"creativity_score\": 1,\n",
      "  \"grammar_score\": 1,\n",
      "  \"justification\": \"The story begins with a coherent phrase but immediately dissolves into an extreme repetition of the word 'to', making it entirely illogical, devoid of any creative development, and grammatically incomplete as a sentence.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Gemini API Connection ---\")\n",
    "!python -m src.main_eval --test-connection\n",
    "\n",
    "print(\"\\n--- Running Full Evaluation ---\")\n",
    "!python -m src.main_eval --perplexity --samples --judge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
